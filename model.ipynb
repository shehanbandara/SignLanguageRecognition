{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f10230fc-7372-4d83-b4da-1018d8924194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fb3c07-0282-454e-b4ef-9e3a9e844522",
   "metadata": {},
   "source": [
    "# Load The Sign Language Gesture Images Dataset\n",
    "\n",
    "Download: https://www.kaggle.com/ahmedkhanak1995/sign-language-gesture-images-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eea98b9-971c-4b8d-8726-97acdf12d9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z Nothing']\n"
     ]
    }
   ],
   "source": [
    "# Sort the data folders in alphabetical order\n",
    "dataFolders = sorted(os.listdir('SignLanguageRecognitionData/'))\n",
    "\n",
    "# Delete .DS_Store if present\n",
    "if dataFolders[0] == '.DS_Store':\n",
    "    dataFolders.pop(0)\n",
    "    \n",
    "print(dataFolders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f5e9772-f3fc-42b6-855e-f289a10f2f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36000, 50, 50, 3)\n",
      "(36000,)\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists for all images and labels in the dataset\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Loop through all data folders\n",
    "for i, label in enumerate(dataFolders):\n",
    "    \n",
    "    # Loop through all images in the data folder\n",
    "    for j in os.listdir('SignLanguageRecognitionData/' + label):\n",
    "        \n",
    "        # Resize the image\n",
    "        image = cv2.resize(cv2.imread('SignLanguageRecognitionData/' + label + '/' + j), (50,50))\n",
    "        \n",
    "        # Append the image and label to its respective list\n",
    "        images.append(image)\n",
    "        labels.append(i)\n",
    "\n",
    "# Convert the images and labels lists to arrays\n",
    "images = np.asarray(images)\n",
    "labels = np.asarray(labels)\n",
    "\n",
    "# Print the shape of the images and labels arrays\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb68f14f-73dc-49fa-ac70-60b7ad9f6aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into 80% training data, 10% validation data, & 10% testing data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(images, labels, test_size=0.2)\n",
    "X_test, X_val, Y_test, Y_val = train_test_split(X_test, Y_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41656569-512e-4acc-82da-0cc1136791f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28800, 50, 50, 3) (28800,)\n",
      "(3600, 50, 50, 3) (3600,)\n",
      "(3600, 50, 50, 3) (3600,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the training, validation, and testing data\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_val.shape, Y_val.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d362a65d-f60a-4ef5-a551-e6c274216540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Y_train, Y_val, & Y_test to One-Hot Encoded Vectors\n",
    "Y_train = to_categorical(Y_train)\n",
    "Y_val = to_categorical(Y_val)\n",
    "Y_test = to_categorical(Y_test)\n",
    "X_train = X_train / 255.\n",
    "X_val = X_val / 255.\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afa80fab-7a17-496d-a175-74bcd2ff3bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 48, 48, 16)        448       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 46, 46, 16)        2320      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 44, 44, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 22, 22, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 20, 20, 32)        4640      \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 18, 18, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 16, 16, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 2, 2, 64)          36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 25)                3225      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 156,697\n",
      "Trainable params: 156,697\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the Sign Language Recognition model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation ='relu', input_shape=(50,50,3)),\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation ='relu'),\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation ='relu'),\n",
    "    tf.keras.layers.MaxPool2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation ='relu'),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation ='relu'),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation ='relu'),\n",
    "    tf.keras.layers.MaxPool2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation ='relu'),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation ='relu'),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation ='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(25, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d97bef-0127-4036-8aa1-a54c4925cf30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
