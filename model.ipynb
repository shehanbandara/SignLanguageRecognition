{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f10230fc-7372-4d83-b4da-1018d8924194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fb3c07-0282-454e-b4ef-9e3a9e844522",
   "metadata": {},
   "source": [
    "# Load The Sign Language Gesture Images Dataset\n",
    "\n",
    "Download: https://www.kaggle.com/ahmedkhanak1995/sign-language-gesture-images-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eea98b9-971c-4b8d-8726-97acdf12d9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z Nothing']\n"
     ]
    }
   ],
   "source": [
    "# Sort the data folders in alphabetical order\n",
    "dataFolders = sorted(os.listdir('SignLanguageRecognitionData/'))\n",
    "\n",
    "# Delete .DS_Store if present\n",
    "if dataFolders[0] == '.DS_Store':\n",
    "    dataFolders.pop(0)\n",
    "    \n",
    "print(dataFolders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f5e9772-f3fc-42b6-855e-f289a10f2f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36000, 50, 50, 3)\n",
      "(36000,)\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists for all images and labels in the dataset\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Loop through all data folders\n",
    "for i, label in enumerate(dataFolders):\n",
    "    \n",
    "    # Loop through all images in the data folder\n",
    "    for j in os.listdir('SignLanguageRecognitionData/' + label):\n",
    "        \n",
    "        # Resize the image\n",
    "        image = cv2.resize(cv2.imread('SignLanguageRecognitionData/' + label + '/' + j), (50,50))\n",
    "        \n",
    "        # Append the image and label to its respective list\n",
    "        images.append(image)\n",
    "        labels.append(i)\n",
    "\n",
    "# Convert the images and labels lists to arrays\n",
    "images = np.asarray(images)\n",
    "labels = np.asarray(labels)\n",
    "\n",
    "# Print the size of the images and labels arrays\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb68f14f-73dc-49fa-ac70-60b7ad9f6aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into 80% training data, 10% validation data, & 10% testing data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(images, labels, test_size=0.8)\n",
    "X_test, X_val, Y_test, Y_val = train_test_split(X_test, Y_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41656569-512e-4acc-82da-0cc1136791f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
